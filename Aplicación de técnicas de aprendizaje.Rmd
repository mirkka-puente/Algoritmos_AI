---
title: "Actividad 1: Aplicación de técnicas de aprendizaje no supervisado sobre datos biológicos"
author: "Mirkka Puente Madrid"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Actividad 1: Aplicación de técnicas de aprendizaje no supervisado sobre datos biológicos

## Preparación del entorno de trabajo (instalación y carga de paquetes adecuados)

### Analisis de componentes principales

```{r PCA}

#Remover todas las variables creadas en environment so far
rm(list=ls())
#Establecer nuestro directorio donde trabajaremos
setwd("C:/Users/User/Desktop/UNIR/Algoritmos_IA/Algoritmos_AI")

#Install libraries
# Instalación
pack_list <- c("ggplot2",
               "dplyr",
               "stats")

for (pack in pack_list) {
  if (!requireNamespace(pack, quietly = TRUE))
    install.packages(pack)
}

# Carga de librerias
library(stats)   # librería para el PCA
library(ggplot2) # librería para hacer la representación gráfica
library(dplyr)

#Guardar data en nuestro environment
file <- "data_1000.csv"
dt <- read.csv(file, fileEncoding="UTF-8-BOM", check.names=FALSE)
lb <- read.csv('labels.csv')
#Prueba
#dt_500 <- read.csv("data_500.csv", fileEncoding="UTF-8-BOM", check.names=FALSE)

# Guardado en un dataframe 
data_frame <- data.frame(sapply(dt[2:1001], as.numeric))

# Estadisticos
summary(data_frame[, 1:10])

# Valores NA y 0
anyNA(data_frame)
na_counts <- colSums((is.na(data_frame)))

any(data_frame == 0)
zero_counts <- colSums(data_frame == 0)
zero_prop   <- zero_counts / nrow(data_frame)
#Determinar si la columna deberia eliminarse
gen_zero <- list()
count <- 1
for (i in seq_along(zero_prop)) {
  if (zero_prop[i] >= 0.9) {
    gen_zero[[count]] <- names(zero_prop)[i]
    count <- count + 1
  }
}

#Eliminar las columnas con un porcentaje de ceros mayor al 90%
dt_denoised <- data_frame %>% select(-any_of(unlist(gen_zero)))


# Podemos hacer un diagrama de cajas para variable y vemos los estadísticos y outliers
boxplot(dt_denoised[, 1:20], main = "Boxplot de los 20 primeros genes")

#Eliminar genes sin variabilidad, si el gen tiene varianza alta, se conserva
vars <- apply(dt_denoised, 2, var) #2 es para columnas, var calcula varianza
dt_high_var <- dt_denoised[, vars > quantile(vars, 0.1)] #calcula el percentil 10 de var

# Funcion prcomp()
#   data: conjunto de datos
#   center: si queremos que las variables esten centradas en cero
#   scale: si queremos que las variables tengan varianza 1

# Calculo de componentes principales con la funcion prcomp
set.seed(1997)
pca.results <- prcomp(dt_high_var, center=TRUE, scale.=FALSE)

# Resultado de las componentes principales
pca.df <- data.frame(pca.results$x)

# Varianza (cuadrado de la desviacion tipica)
varianzas <- pca.results$sdev^2

# Total de la varianza de los datos
total.varianza <- sum(varianzas)

# Varianza explicada por cada componente principal
varianza.explicada <- varianzas/total.varianza

# Calculamos la varianza acumulada 
varianza.acumulada <- cumsum(varianza.explicada)

# Tomamos el numero de componentes principales que explican el 90% de la varianza
n.pc <- min(which(varianza.acumulada > 0.90))

# Etiquetas de los ejes del gráfico
x_label <- paste0(paste('PC1', round(varianza.explicada[1] * 100, 2)), '%')
y_label <- paste0(paste('PC2', round(varianza.explicada[2] * 100, 2)), '%')

# Representación gráfica de las primeras dos componentes principales respecto a los datos
ggplot(pca.df, aes(x=PC1, y=PC2, color=lb$Class)) +
  geom_point(size=3) +
  scale_color_manual(values=c('red', 'blue', 'green', 'orange', 'purple')) +
  labs(title='PCA - Types of Cancer', x=x_label, y=y_label, color='Grupo') +
  theme_minimal() +
  theme(panel.grid.major = element_line(color="gray90"), panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = "gray95"), plot.title = element_text(hjust = 0.5))


```
### Multidimensional Scaling 

```{r MDS}
#Remover todas las variables creadas en environment so far
rm(list=ls())
#Establecer nuestro directorio donde trabajaremos
setwd("C:/Users/User/Desktop/UNIR/Algoritmos_IA/Algoritmos_AI")

#Install libraries
# Instalación
pack_list <- c("ggplot2",
               "dplyr",
               "stats")

for (pack in pack_list) {
  if (!requireNamespace(pack, quietly = TRUE))
    install.packages(pack)
}

# Carga de librerias
library(stats)   # librería para el PCA
library(ggplot2) # librería para hacer la representación gráfica
library(dplyr)

#Guardar data en nuestro environment
file <- "data_1000.csv"
dt <- read.csv(file, fileEncoding="UTF-8-BOM", check.names=FALSE)
lb <- read.csv('labels.csv')
#Prueba
#dt_500 <- read.csv("datos_500.csv", fileEncoding="UTF-8-BOM", check.names=FALSE)

# Guardado en un dataframe 
data_frame <- data.frame(sapply(dt[2:1001], as.numeric))

# Valores NA y 0
anyNA(data_frame)
na_counts <- colSums((is.na(data_frame)))

any(data_frame == 0)
zero_counts <- colSums(data_frame == 0)
zero_prop   <- zero_counts / nrow(data_frame)
#Determinar si la columna deberia eliminarse
gen_zero <- list()
count <- 1
for (i in seq_along(zero_prop)) {
  if (zero_prop[i] >= 0.9) {
    gen_zero[[count]] <- names(zero_prop)[i]
    count <- count + 1
  }
}

#Eliminar las columnas con un porcentaje de ceros mayor al 90%
dt_denoised <- data_frame %>% select(-any_of(unlist(gen_zero)))

#Eliminar genes sin variabilidad, si el gen tiene varianza alta, se conserva
vars <- apply(dt_denoised, 2, var) #2 es para columnas, var calcula varianza
dt_high_var <- dt_denoised[, vars > quantile(vars, 0.1)] #calcula el percentil 10 de var


# Algoritmo #

# Funcion cmdscale()
#   d: matriz de distancias (usaremos la funcion dist)
#   k: numero que indica el tamaño final de los datos (max num de variables)
#   eig: si calculamos autovalores de las variables. Nos sirve para el calculo 
#        de la varianza explicada, es decir, para coger las columnas de mayor
#        variabilidad
#   x.ret: para devolver la matriz de distancias que calcule el algoritmo

#   points: dataframe de tamaño k que representa las nuevas coordenadas
#   eig: vector con los autovalores para elegir el numero de dimensiones


#a. Necesitamos que nuestros genes esten en las filas y expresion en columnas para
#calcular correlación entre muestras.
dt_transpuesta <- t(dt_high_var)

#b. Queremos similitud en patrones de expresión, no valores absolutos. 
#Usar correlacion Pearson ya que Pearson captura el patrón de expresión
corr <- cor(dt_transpuesta, method = 'pearson')

#c. Utilizamos la funcion as.dist para calcular la matriz de distancias 
dt_dist <- 1 - corr
distances <- as.dist(dt_dist)

# Utilizamos la funcon cmdscale para realizar el MSD
mds.results <- cmdscale(distances, eig=TRUE, k=2, x.ret=TRUE)

# Calculamos la varianza explicada
varianza.explicada <- mds.results$eig/sum(mds.results$eig) * 100

# Sacamos en un dataframe los puntos del mds
mds.df <- data.frame(mds.results$points)

# Grafico
ggplot(mds.df, aes(x=X1, y=X2, color=lb$Class)) +
  geom_point(size=3) + 
  scale_color_manual(values=c("red", "blue", "green", "orange", "purple")) +
  labs(title="MDS - Types of Cancer", x="Dimension 1 (X1)", y="Dimension 2 (X2)", color = "Grupo") +
  theme_minimal() + 
  theme(panel.grid.major = element_line(color = "gray90"), panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = "gray95"), plot.title=element_text(hjust=0.5))

##Los tipos de cáncer tienen firmas de expresión distintas, pero no todos por igual.
#Algunos (KIRC, PRAD) se separan bien.
#Otros (COAD, LUAD, BRCA) comparten más similitud global.

```

### T-distributed Stochastic Neighbor Embedding

```{r t-SNE }

#Remover todas las variables creadas en environment so far
rm(list=ls())
#Establecer nuestro directorio donde trabajaremos
setwd("C:/Users/User/Desktop/UNIR/Algoritmos_IA/Algoritmos_AI")

#Install libraries
# Instalación
pack_list <- c("ggplot2",
               "dplyr",
               "Rtsne")

for (pack in pack_list) {
  if (!requireNamespace(pack, quietly = TRUE))
    install.packages(pack)
}


# Carga de librerias
library(ggplot2)
library(Rtsne)
library(dplyr)

#Guardar data en nuestro environment
file <- "data_1000.csv"
dt <- read.csv(file, fileEncoding="UTF-8-BOM", check.names=FALSE)
lb <- read.csv('labels.csv')
#Prueba
#dt_500 <- read.csv("datos_500.csv", fileEncoding="UTF-8-BOM", check.names=FALSE)

# Guardado en un dataframe 
dt_frame <- data.frame(sapply(dt[2:1001], as.numeric))

# Valores NA y 0
anyNA(dt_frame)
na_counts <- colSums((is.na(dt_frame)))

any(dt_frame == 0)
zero_counts <- colSums(dt_frame == 0)
zero_prop   <- zero_counts / nrow(dt_frame)
#Determinar si la columna deberia eliminarse
gen_zero <- list()
count <- 1
for (i in seq_along(zero_prop)) {
  if (zero_prop[i] >= 0.9) {
    gen_zero[[count]] <- names(zero_prop)[i]
    count <- count + 1
  }
}

#Eliminar las columnas con un porcentaje de ceros mayor al 90%
dt_denoised <- dt_frame %>% select(-any_of(unlist(gen_zero)))

#Eliminar genes sin variabilidad, si el gen tiene varianza alta, se conserva
vars <- apply(dt_denoised, 2, var) #2 es para columnas, var calcula varianza
dt_high_var <- dt_denoised[, vars > quantile(vars, 0.1)] #calcula el percentil 10 de var

#Escalar mis datos porque t-SNE espera escalas similares.

dt_scaled <- scale(dt_high_var) 

# Algoritmo
# funcion Rtsne()
#   X: datos sobre los que reduciremos la dimensionalidad
#   dims: tamaño final del conjunto de datos (mejor <=3) por eficiencia
#   perplexity: importa para la calidad de clusters
#   theta: importa para que corra mas rapido
#   pca: TRUE para que la funcion haga un PCR internamente antes del t-SNE

#   Variable Y con matriz del t-SNE

set.seed(1997)
tsne <- Rtsne(X=dt_scaled, perplexity = 50, theta = 0.5, pca = TRUE)
tsne_result <- data.frame(tsne$Y)

# Graficamos
ggplot(tsne_result, aes(x = X1, y = X2, color = lb$Class)) +
geom_point(size = 3) +
scale_color_manual(values = c("red", "blue", "green", "orange", "purple")) +
labs(title = "t-SNE - Types of cancer", x = "Dim 1", y = "Dim 2", color = "Grupo") +
theme_classic() +
theme(panel.grid.major = element_line(color = "gray90"), panel.grid.minor = element_blank(),
panel.background = element_rect(fill = "gray95"), plot.title=element_text(hjust=0.5))

```

### Isometric Mapping

```{r isomap}

#Remover todas las variables creadas en environment so far
rm(list=ls())
#Establecer nuestro directorio donde trabajaremos
setwd("C:/Users/User/Desktop/UNIR/Algoritmos_IA/Algoritmos_AI")

#Install libraries
# Instalación
pack_list <- c("ggplot2",
               "dplyr",
               "BiocManager",
               "plotly"
               )

for (pack in pack_list) {
  if (!requireNamespace(pack, quietly = TRUE))
    install.packages(pack)
}
#BiocManager::install("RDRToolbox")

# Carga de librerias
library(ggplot2)
library(dplyr)
library(BiocManager)
library(RDRToolbox)
library(plotly)

#Guardar data en nuestro environment
file <- "data_1000.csv"
dt <- read.csv(file, fileEncoding="UTF-8-BOM", check.names=FALSE)
lb <- read.csv('labels.csv')
#Prueba
dt_500 <- read.csv("datos_500.csv", fileEncoding="UTF-8-BOM", check.names=FALSE)

# Guardado en un dataframe 
dt_frame <- data.frame(sapply(dt_500[2:501], as.numeric))

# Valores NA y 0
anyNA(dt_frame)
na_counts <- colSums((is.na(dt_frame)))

any(dt_frame == 0)
zero_counts <- colSums(dt_frame == 0)
zero_prop   <- zero_counts / nrow(dt_frame)
#Determinar si la columna deberia eliminarse
gen_zero <- list()
count <- 1
for (i in seq_along(zero_prop)) {
  if (zero_prop[i] >= 0.9) {
    gen_zero[[count]] <- names(zero_prop)[i]
    count <- count + 1
  }
}

#Eliminar las columnas con un porcentaje de ceros mayor al 90%
dt_denoised <- dt_frame %>% select(-any_of(unlist(gen_zero)))

#Eliminar genes sin variabilidad, si el gen tiene varianza alta, se conserva
vars <- apply(dt_denoised, 2, var) #2 es para columnas, var calcula varianza
dt_high_var <- dt_denoised[, vars > quantile(vars, 0.1)] #calcula el percentil 10 de var

#Escalar mis datos porque isometric mapping espera escalas similares.
dt_scaled <- scale(dt_high_var) 

# Algoritmo

# Funcion Isomap()
#   data -> datos (matriz) sobre los que haremos reduccion de dimensionalidad
#   dim -> dimensiones de las columnas del espacio reducido
#   k -> numero de vecinos cercanos a cada punto. A mayor k mayor computacion
#   potResiduals -> devuelve la varianza explicada por las diferentes dimensiones

#   Si se ha elegido una unica dimension devuelve una matriz
#   Si se ha elegido un vector de dimensiones devolvera una matriz por cada elemento del vector

# Calculamos isomap de 1 a 5 dimensiones y con 5 vecinos 
isomap.results = Isomap(data=dt_scaled, dims=1:5, k=30, plotResiduals=TRUE)

# Dataframe con los puntos que queremos dibujar en el plano 3D
isomap.df <- data.frame(isomap.results$dim3) 

# Graficamos
isomap.df$Class <- lb$Class                  # add labels

# Plot
plot_ly(isomap.df, x = ~X1, y = ~X2, z = ~X3, color = ~Class, 
        colors = c("red", "blue", "green", "orange", "purple"),
        type = "scatter3d", mode = "markers") %>%
  layout(title = "Isomap 3D - Types of Cancer")


```


